# Course Aggregator - Horizontal Repository for Open Courses

A comprehensive course aggregation system that collects courses from multiple MOOC platforms, provides a unified search interface, and uses Apache Spark for large-scale machine learning recommendations and clustering.

## ğŸ¯ Project Overview

This project implements a horizontal repository/aggregator that:
- Collects course data from multiple external repositories (EDX, Coursera, etc.)
- Provides a unified React front-end for search, filtering, and exploration
- Uses Apache Spark for ML-based recommendations and course clustering
- Offers RESTful APIs for course management and analytics

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   React     â”‚  Front-end (Search, Filters, Course Details, Analytics)
â”‚  Frontend   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ REST API
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚   Express   â”‚  Back-end API Server
â”‚   Backend   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
   â”Œâ”€â”€â”€â”´â”€â”€â”€â”
   â”‚       â”‚
â”Œâ”€â”€â–¼â”€â”€â” â”Œâ”€â–¼â”€â”€â”€â”€â”
â”‚Mongoâ”‚ â”‚Spark â”‚  Data Storage & ML Processing
â”‚ DB  â”‚ â”‚ ML   â”‚
â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ Features

### Front-end (React)
- âœ… Course search with full-text search
- âœ… Advanced filtering (language, level, category, source)
- âœ… Course details page with full information
- âœ… Similar courses recommendations (Spark-based)
- âœ… Analytics dashboard with statistics
- âœ… Responsive Material-UI design

### Back-end (Node.js/Express)
- âœ… RESTful API endpoints
- âœ… Course CRUD operations
- âœ… Pagination and filtering
- âœ… Connector system for multiple course sources
- âœ… Automatic synchronization scheduler
- âœ… Analytics endpoints

### Data Aggregation
- âœ… EDX connector (with mock data)
- âœ… Coursera connector (with mock data)
- âœ… Unified data schema
- âœ… Full and incremental sync support

### Spark ML Pipeline
- âœ… Text preprocessing (tokenization, stop words removal)
- âœ… Feature extraction (TF-IDF, categorical encoding)
- âœ… K-means clustering
- âœ… Course similarity calculation
- âœ… Integration with MongoDB

## ğŸš€ Getting Started

### Prerequisites

- Node.js (v14 or higher)
- MongoDB (v4.4 or higher)
- Python 3.8+ (for Spark)
- Apache Spark 3.5.0
- Java 8 or higher (required for Spark)

### Installation

1. **Clone the repository**
```bash
git clone <repository-url>
cd course-aggregator
```

2. **Install backend dependencies**
```bash
npm install
```

3. **Install frontend dependencies**
```bash
cd frontend
npm install
cd ..
```

4. **Install Spark dependencies**
```bash
cd spark
pip install -r requirements.txt
cd ..
```

5. **Set up environment variables**
```bash
cp .env.example .env
# Edit .env with your configuration
```

6. **Start MongoDB**
```bash
# Make sure MongoDB is running on localhost:27017
mongod
```

### Running the Application

1. **Start the backend server**
```bash
npm start
# or for development with auto-reload
npm run dev
```

The backend will run on `http://localhost:5000`

2. **Start the frontend**
```bash
npm run client
```

The frontend will run on `http://localhost:3000`

3. **Run Spark ML Pipeline**
```bash
# Make sure Spark is properly configured
spark-submit spark/ml_pipeline.py
```

### Initial Data Sync

To populate the database with courses, trigger a sync:

```bash
# Sync from EDX
curl -X POST http://localhost:5000/api/sync/edx

# Sync from Coursera
curl -X POST http://localhost:5000/api/sync/coursera

# Full sync
curl -X POST http://localhost:5000/api/sync/edx -H "Content-Type: application/json" -d '{"fullSync": true}'
```

## ğŸ“ Project Structure

```
course-aggregator/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ server.js              # Express server
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ Course.js         # MongoDB course model
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ courses.js        # Course endpoints
â”‚   â”‚   â”œâ”€â”€ sync.js           # Sync endpoints
â”‚   â”‚   â””â”€â”€ analytics.js      # Analytics endpoints
â”‚   â”œâ”€â”€ connectors/
â”‚   â”‚   â”œâ”€â”€ index.js          # Connector registry
â”‚   â”‚   â”œâ”€â”€ baseConnector.js  # Base connector class
â”‚   â”‚   â”œâ”€â”€ edxConnector.js   # EDX connector
â”‚   â”‚   â””â”€â”€ courseraConnector.js # Coursera connector
â”‚   â””â”€â”€ config/
â”‚       â””â”€â”€ scheduler.js       # Automatic sync scheduler
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/       # React components
â”‚   â”‚   â”œâ”€â”€ pages/           # Page components
â”‚   â”‚   â”œâ”€â”€ services/        # API services
â”‚   â”‚   â””â”€â”€ App.js           # Main app component
â”‚   â””â”€â”€ public/
â”œâ”€â”€ spark/
â”‚   â”œâ”€â”€ ml_pipeline.py       # Spark ML pipeline
â”‚   â””â”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ package.json
â””â”€â”€ README.md
```

## ğŸ”Œ API Endpoints

### Courses
- `GET /api/courses` - List courses with filters and pagination
- `GET /api/courses/:id` - Get course details
- `GET /api/courses/:id/similar` - Get similar courses (Spark recommendations)
- `GET /api/courses/filters/options` - Get available filter options

### Sync
- `POST /api/sync/:source` - Trigger sync from specific source
- `GET /api/sync/status` - Get sync status for all sources

### Analytics
- `GET /api/analytics` - Get analytics data

## ğŸ§ª Testing

### Manual Testing

1. **Test API endpoints**
```bash
# Get all courses
curl http://localhost:5000/api/courses

# Get course by ID
curl http://localhost:5000/api/courses/<course-id>

# Get similar courses
curl http://localhost:5000/api/courses/<course-id>/similar
```

2. **Test frontend**
- Navigate to `http://localhost:3000`
- Search for courses
- Apply filters
- View course details
- Check analytics dashboard

## ğŸ“Š Database Schema

### Course Model
```javascript
{
  title: String,
  description: String,
  shortDescription: String,
  keywords: [String],
  category: String,
  language: String,
  level: String (beginner/intermediate/advanced),
  source: {
    repositoryName: String,
    repositoryUrl: String,
    sourceId: String
  },
  accessLink: String,
  lastUpdated: Date,
  metadata: Object,
  sparkSimilarity: [{
    courseId: ObjectId,
    similarity: Number
  }],
  clusterId: Number
}
```

## ğŸ”§ Configuration

### Environment Variables

- `PORT` - Backend server port (default: 5000)
- `MONGODB_URI` - MongoDB connection string
- `REACT_APP_API_URL` - Frontend API URL
- `SPARK_MASTER` - Spark master URL

## ğŸ“ Machine Learning Pipeline

The Spark ML pipeline performs:

1. **Text Preprocessing**
   - Tokenization
   - Stop words removal
   - TF-IDF vectorization

2. **Feature Engineering**
   - Categorical encoding (category, level, language)
   - Feature vector assembly

3. **Clustering**
   - K-means clustering (k=5)
   - Cluster assignment

4. **Similarity Calculation**
   - Cosine similarity between courses
   - Top 10 similar courses per course

## ğŸ“ Notes

- The connectors currently use mock data. In production, replace with actual API calls to EDX, Coursera, etc.
- The Spark pipeline requires MongoDB connector for Spark. Install it separately if needed.
- Automatic syncs run daily at 2 AM (configurable in `backend/config/scheduler.js`)

## ğŸš§ Future Enhancements

- [ ] User accounts and personalization
- [ ] More course sources
- [ ] Advanced ML models (collaborative filtering, embeddings)
- [ ] Admin dashboard
- [ ] Real-time recommendations
- [ ] Course ratings and reviews

## ğŸ“„ License

MIT License

## ğŸ‘¥ Authors

Course Aggregator Project Team

---

**Note**: This is a demonstration project. For production use, implement proper error handling, authentication, rate limiting, and security measures.

